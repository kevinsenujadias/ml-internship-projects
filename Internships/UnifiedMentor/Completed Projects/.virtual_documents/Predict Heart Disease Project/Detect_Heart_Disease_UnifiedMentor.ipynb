import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import (confusion_matrix, classification_report,
                             accuracy_score, precision_score, recall_score,
                             f1_score, roc_curve, roc_auc_score)


df = pd.read_csv('dataset.csv')


df.head()


df.info()


df.isnull().sum()


# Cell 7 - Check target distribution
print("Target Distribution:")
print(df['target'].value_counts())
print(f"\nClass 0 (No Disease): {(df['target']==0).sum()} ({(df['target']==0).sum()/len(df)*100:.1f}%)")
print(f"Class 1 (Heart Disease): {(df['target']==1).sum()} ({(df['target']==1).sum()/len(df)*100:.1f}%)")


plt.figure(figsize=(8, 5))
sns.countplot(x='target', data=df, palette='Set2')
plt.title('Target Distribution (Heart Disease)', fontsize=14, fontweight='bold')
plt.xlabel('Target (0 = No Disease, 1 = Heart Disease)')
plt.ylabel('Count')
plt.show()


# Cell: Correlation with target
correlations = df.corr()['target'].sort_values(ascending=False)
print("Features most correlated with Heart Disease:")
print(correlations)


# Cell: Correlation heatmap
plt.figure(figsize=(10, 8))
sns.heatmap(df.corr(), annot=True, fmt='.2f', cmap='coolwarm', center=0)
plt.title('Feature Correlation Heatmap', fontsize=14, fontweight='bold')
plt.tight_layout()
plt.show()


feature_columns = [col for col in df.columns if col != 'target']


print(f"ðŸ“‹ Using {len(feature_columns)} features:")
for i, feat in enumerate(feature_columns, 1):
    corr = df.corr()['target'][feat]
    strength = "ðŸ”´ Strong" if abs(corr) > 0.4 else "ðŸŸ¡ Moderate" if abs(corr) > 0.2 else "âšª Weak"
    print(f"  {i:2d}. {feat:25s} {strength} (corr: {corr:+.3f})")

X = df[feature_columns]
y = df['target']

print(f"\nX shape: {X.shape}")
print(f"y shape: {y.shape}")


# Cell: Feature Scaling
print("ðŸ”§ Scaling features using StandardScaler...")
print("\nðŸ’¡ Why scaling is important:")
print("   â€¢ ST slope ranges: 1-3")
print("   â€¢ Max heart rate ranges: 71-202")
print("   â€¢ Different scales slow down Gradient Descent!")
print("   â€¢ StandardScaler makes all features mean=0, std=1")

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
X_scaled = pd.DataFrame(X_scaled, columns=feature_columns)

print("\nScaling complete!")
print("\nBefore vs After (first 3 samples):")
print("\nBefore:")
print(X.head(3))
print("\nAfter (standardized):")
print(X_scaled.head(3))


# Cell: Split data
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y,
    test_size=0.2,
    random_state=42,
    stratify=y  # Keeps 47-53 balance in both sets!
)

print("Data split complete!")
print(f"\nðŸ“š Training set: {X_train.shape[0]} samples")
print(f"   Class 0: {sum(y_train==0)} ({sum(y_train==0)/len(y_train)*100:.1f}%)")
print(f"   Class 1: {sum(y_train==1)} ({sum(y_train==1)/len(y_train)*100:.1f}%)")

print(f"\nðŸ§ª Testing set: {X_test.shape[0]} samples")
print(f"   Class 0: {sum(y_test==0)} ({sum(y_test==0)/len(y_test)*100:.1f}%)")
print(f"   Class 1: {sum(y_test==1)} ({sum(y_test==1)/len(y_test)*100:.1f}%)")


model = LogisticRegression(max_iter=1000, random_state=42)
model.fit(X_train, y_train)


# Cell: Show model parameters
print("Model Parameters:")
print(f"Intercept: {model.intercept_[0]:.4f}")

print("\nFeature Coefficients:")
for feature, coef in zip(feature_columns, model.coef_[0]):
    print(f"{feature:25s}: {coef:.4f}")


# Cell: Make predictions
y_test_pred = model.predict(X_test)
y_test_prob = model.predict_proba(X_test)[:, 1]

print("Predictions completed!")


# Cell: Show sample predictions
print("Sample Predictions:")
for i in range(10):
    print(f"Actual: {y_test.iloc[i]}, Predicted: {y_test_pred[i]}, Probability: {y_test_prob[i]:.2f}")


from sklearn.metrics import roc_curve, auc

fpr, tpr, _ = roc_curve(y_test, y_test_prob)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(6, 5))
plt.plot(fpr, tpr, label=f"AUC = {roc_auc:.2f}")
plt.plot([0, 1], [0, 1], linestyle="--")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve")
plt.legend()
plt.show()




